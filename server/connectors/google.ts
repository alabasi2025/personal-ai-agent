/**
 * ğŸŒŸ Google AI Connector - Ù…ÙˆØµÙ„ Google AI
 * ÙŠØªØµÙ„ Ø¨Ù€ Gemini API Ùˆ Google AI Ultra
 */

import { GoogleGenerativeAI, GenerativeModel, Content, Part } from '@google/generative-ai';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ø§Ù„Ø£Ù†ÙˆØ§Ø¹
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export interface GoogleAIConfig {
    apiKey: string;
    model?: string;          // gemini-pro, gemini-pro-vision, etc.
    maxTokens?: number;
    temperature?: number;
}

export interface ChatMessage {
    role: 'user' | 'model';
    content: string;
}

export interface ChatResponse {
    success: boolean;
    content?: string;
    error?: string;
    tokensUsed?: number;
    model?: string;
}

export interface AnalysisResult {
    success: boolean;
    analysis?: string;
    summary?: string;
    keyPoints?: string[];
    error?: string;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Google AI Connector Class
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class GoogleAIConnector {
    private genAI: GoogleGenerativeAI;
    private model: GenerativeModel;
    private config: GoogleAIConfig;
    private chatHistory: Content[] = [];

    constructor(config: GoogleAIConfig) {
        this.config = {
            model: 'gemini-pro',
            maxTokens: 8192,
            temperature: 0.7,
            ...config
        };

        this.genAI = new GoogleGenerativeAI(this.config.apiKey);
        this.model = this.genAI.getGenerativeModel({
            model: this.config.model!,
            generationConfig: {
                maxOutputTokens: this.config.maxTokens,
                temperature: this.config.temperature
            }
        });
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /**
     * Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø­Ø¯Ø©
     */
    async chat(message: string, systemPrompt?: string): Promise<ChatResponse> {
        try {
            let prompt = message;
            
            if (systemPrompt) {
                prompt = `${systemPrompt}\n\n---\n\n${message}`;
            }

            const result = await this.model.generateContent(prompt);
            const response = result.response;
            const text = response.text();

            return {
                success: true,
                content: text,
                model: this.config.model
            };
        } catch (error: any) {
            console.error('âŒ Google AI chat error:', error);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Ù…Ø­Ø§Ø¯Ø«Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
     */
    async chatWithHistory(messages: ChatMessage[], systemPrompt?: string): Promise<ChatResponse> {
        try {
            // ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù„ØµÙŠØºØ© Gemini
            const contents: Content[] = messages.map(msg => ({
                role: msg.role === 'user' ? 'user' : 'model',
                parts: [{ text: msg.content }]
            }));

            // Ø¥Ø¶Ø§ÙØ© system prompt ÙƒØ£ÙˆÙ„ Ø±Ø³Ø§Ù„Ø©
            if (systemPrompt) {
                contents.unshift({
                    role: 'user',
                    parts: [{ text: `[System Instructions]\n${systemPrompt}\n[End System Instructions]` }]
                });
                contents.splice(1, 0, {
                    role: 'model',
                    parts: [{ text: 'ÙÙ‡Ù…Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª. Ø³Ø£ØªØ¨Ø¹Ù‡Ø§.' }]
                });
            }

            const chat = this.model.startChat({
                history: contents.slice(0, -1)
            });

            const lastMessage = contents[contents.length - 1];
            const result = await chat.sendMessage(lastMessage.parts[0].text || '');
            const response = result.response;
            const text = response.text();

            return {
                success: true,
                content: text,
                model: this.config.model
            };
        } catch (error: any) {
            console.error('âŒ Google AI chat with history error:', error);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Ø¨Ø¯Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©
     */
    startNewChat(): void {
        this.chatHistory = [];
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Ø§Ù„ØªØ­Ù„ÙŠÙ„
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /**
     * ØªØ­Ù„ÙŠÙ„ Ù†Øµ
     */
    async analyzeText(text: string, instructions?: string): Promise<AnalysisResult> {
        try {
            const prompt = `
${instructions || 'Ø­Ù„Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆÙ‚Ø¯Ù… Ù…Ù„Ø®ØµØ§Ù‹ ÙˆØ§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:'}

Ø§Ù„Ù†Øµ:
---
${text}
---

Ù‚Ø¯Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„ØµÙŠØºØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:
## Ø§Ù„Ù…Ù„Ø®Øµ
[Ù…Ù„Ø®Øµ Ù…ÙˆØ¬Ø²]

## Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
- Ù†Ù‚Ø·Ø© 1
- Ù†Ù‚Ø·Ø© 2
- Ù†Ù‚Ø·Ø© 3

## Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ
[Ø§Ù„ØªØ­Ù„ÙŠÙ„]
`;

            const result = await this.model.generateContent(prompt);
            const response = result.response.text();

            // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
            const summaryMatch = response.match(/## Ø§Ù„Ù…Ù„Ø®Øµ\n([\s\S]*?)(?=##|$)/);
            const pointsMatch = response.match(/## Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n([\s\S]*?)(?=##|$)/);

            const keyPoints = pointsMatch
                ? pointsMatch[1].split('\n').filter(line => line.trim().startsWith('-')).map(line => line.trim().substring(1).trim())
                : [];

            return {
                success: true,
                analysis: response,
                summary: summaryMatch ? summaryMatch[1].trim() : undefined,
                keyPoints
            };
        } catch (error: any) {
            console.error('âŒ Google AI analyze error:', error);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * ØªØ­Ù„ÙŠÙ„ Ù…Ù‡Ù…Ø© ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
     */
    async analyzeTask(task: string): Promise<{
        needsExecution: boolean;
        needsCoding: boolean;
        needsAnalysis: boolean;
        needsResearch: boolean;
        suggestedTool: 'manus' | 'cursor' | 'google';
        reasoning: string;
    }> {
        try {
            const prompt = `
Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ù‡Ø§Ù… Ø°ÙƒÙŠ. Ø­Ù„Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ­Ø¯Ø¯ Ù†ÙˆØ¹Ù‡Ø§ ÙˆØ§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù‡Ø§.

Ø§Ù„Ù…Ù‡Ù…Ø©: "${task}"

Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
1. **manus** - Ù„Ù„ØªÙ†ÙÙŠØ° Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² (Ø£ÙˆØ§Ù…Ø± shellØŒ Ø¥Ø¯Ø§Ø±Ø© Ù…Ù„ÙØ§ØªØŒ gitØŒ ØªØ´ØºÙŠÙ„ Ø¨Ø±Ø§Ù…Ø¬)
2. **cursor** - Ù„Ù„Ø¨Ø±Ù…Ø¬Ø© ÙˆØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ (Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø§Ø±ÙŠØ¹ØŒ ÙƒØªØ§Ø¨Ø© ÙƒÙˆØ¯ØŒ ØªØ¹Ø¯ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø¨Ø±Ù…Ø¬ÙŠØ©)
3. **google** - Ù„Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø£Ø³Ø¦Ù„Ø©ØŒ ØªØ­Ù„ÙŠÙ„ØŒ Ø¨Ø­Ø«ØŒ Ø´Ø±Ø­)

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·:
{
    "needsExecution": true/false,
    "needsCoding": true/false,
    "needsAnalysis": true/false,
    "needsResearch": true/false,
    "suggestedTool": "manus" Ø£Ùˆ "cursor" Ø£Ùˆ "google",
    "reasoning": "Ø§Ù„Ø³Ø¨Ø¨"
}
`;

            const result = await this.model.generateContent(prompt);
            const response = result.response.text();

            // Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON
            const jsonMatch = response.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                return JSON.parse(jsonMatch[0]);
            }

            // Ø§ÙØªØ±Ø§Ø¶ÙŠ
            return {
                needsExecution: false,
                needsCoding: false,
                needsAnalysis: true,
                needsResearch: false,
                suggestedTool: 'google',
                reasoning: 'Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨ÙˆØ¶ÙˆØ­'
            };
        } catch (error: any) {
            console.error('âŒ Google AI task analysis error:', error);
            return {
                needsExecution: false,
                needsCoding: false,
                needsAnalysis: true,
                needsResearch: false,
                suggestedTool: 'google',
                reasoning: error.message
            };
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /**
     * ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯
     */
    async generateCode(description: string, language: string): Promise<ChatResponse> {
        const prompt = `
Ø£Ù†Øª Ù…Ø¨Ø±Ù…Ø¬ Ø®Ø¨ÙŠØ±. Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ ${language} Ù„Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:

${description}

Ù‚ÙˆØ§Ø¹Ø¯:
- Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ Ù†Ø¸ÙŠÙ ÙˆÙ‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©
- Ø£Ø¶Ù ØªØ¹Ù„ÙŠÙ‚Ø§Øª ØªÙˆØ¶ÙŠØ­ÙŠØ©
- Ø§ØªØ¨Ø¹ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª
- Ø§Ù„ÙƒÙˆØ¯ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¬Ø§Ù‡Ø²Ø§Ù‹ Ù„Ù„ØªØ´ØºÙŠÙ„

Ø£Ø¹Ø¯ Ø§Ù„ÙƒÙˆØ¯ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠØŒ Ø¯Ø§Ø®Ù„ block ÙƒÙˆØ¯:
\`\`\`${language}
// Ø§Ù„ÙƒÙˆØ¯ Ù‡Ù†Ø§
\`\`\`
`;

        return this.chat(prompt);
    }

    /**
     * ØªÙ„Ø®ÙŠØµ Ù†Øµ
     */
    async summarize(text: string, maxLength?: number): Promise<ChatResponse> {
        const prompt = `
Ù„Ø®Øµ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ${maxLength ? `ÙÙŠ Ø­Ø¯ÙˆØ¯ ${maxLength} ÙƒÙ„Ù…Ø©` : 'Ø¨Ø´ÙƒÙ„ Ù…ÙˆØ¬Ø²'}:

${text}
`;

        return this.chat(prompt);
    }

    /**
     * ØªØ±Ø¬Ù…Ø© Ù†Øµ
     */
    async translate(text: string, targetLanguage: string): Promise<ChatResponse> {
        const prompt = `ØªØ±Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ ${targetLanguage}:\n\n${text}`;
        return this.chat(prompt);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /**
     * ØªØºÙŠÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
     */
    setModel(modelName: string): void {
        this.config.model = modelName;
        this.model = this.genAI.getGenerativeModel({
            model: modelName,
            generationConfig: {
                maxOutputTokens: this.config.maxTokens,
                temperature: this.config.temperature
            }
        });
    }

    /**
     * ØªØºÙŠÙŠØ± Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©
     */
    setTemperature(temperature: number): void {
        this.config.temperature = temperature;
        this.model = this.genAI.getGenerativeModel({
            model: this.config.model!,
            generationConfig: {
                maxOutputTokens: this.config.maxTokens,
                temperature
            }
        });
    }

    /**
     * Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØµÙ„
     */
    getInfo(): { name: string; model: string; temperature: number } {
        return {
            name: 'Google AI (Gemini)',
            model: this.config.model!,
            temperature: this.config.temperature!
        };
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Factory Function
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export function createGoogleAIConnector(apiKey: string, model?: string): GoogleAIConnector {
    return new GoogleAIConnector({
        apiKey,
        model: model || 'gemini-pro'
    });
}
